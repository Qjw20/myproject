import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors

import json
import torch
import math

import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(filename='./logs/eval/log_eval_loca_sfe2_crop_padding_32_lut112_overlay.txt', level=logging.INFO,
                    format='%(asctime)s [%(levelname)s]: %(message)s')

original_dir = "/opt/data/private/data/blueberry2"
original_train_val_test_path = os.path.join(original_dir, "train_val_test.json")
pred_dir = "./results/predicts/predict_loca_sfe2_crop_padding_32_lut112"
save_folder = "./results/plots/plot_prediction_loca_sfe2_crop_padding_32_lut112" 

def create_folder_if_not_exists(folder_path):
    if not os.path.exists(folder_path):
        os.makedirs(folder_path)
        print(f"æ–‡ä»¶å¤¹ '{folder_path}' ä¸å­˜åœ¨ï¼Œå·²åˆ›å»ºæˆåŠŸã€‚")
    else:
        print(f"æ–‡ä»¶å¤¹ '{folder_path}' å·²å­˜åœ¨ã€‚")

create_folder_if_not_exists(save_folder)

ae = 0
se = 0
# è¯»å–JSONæ–‡ä»¶
with open(original_train_val_test_path, 'r') as f:
    data = json.load(f)

# è·å–æµ‹è¯•é›†çš„æ–‡ä»¶ååˆ—è¡¨
test_imagenames = data['test']
val_imagenames = data['val']

split = "test"
imagenames = test_imagenames

# éå†æµ‹è¯•é›†æ–‡ä»¶ååˆ—è¡¨
for imagename in imagenames:
    # åœ¨imagesæ–‡ä»¶å¤¹ä¸­æŸ¥æ‰¾åŒ…å« imagename çš„æ–‡ä»¶å
    pred_imagenames = []
    for pred_imagename in os.listdir(pred_dir):
        if imagename[:-4] in pred_imagename:
            pred_imagenames.append(pred_imagename)
    # æ‰“å°ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶ååˆ—è¡¨
    # print(pred_imagenames)
    # åœ¨imagesæ–‡ä»¶å¤¹ä¸­æŸ¥æ‰¾åŒ…å« imagename çš„æ–‡ä»¶å
    pred_imagenames = []
    for pred_imagename in os.listdir(pred_dir):
        if imagename[:-4] in pred_imagename:
            pred_imagenames.append(pred_imagename)
    # æ‰“å°ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶ååˆ—è¡¨

    # è¯»å–åŸå›¾åƒ
    original_image_path = os.path.join(original_dir, "images", imagename)
    original_image = cv2.imread(original_image_path)
    # è·å–å›¾åƒçš„å°ºå¯¸
    width, height = original_image.shape[1], original_image.shape[0]
    # å®šä¹‰æœ‰æ•ˆå°ºå¯¸
    crop_size_before_padding = (1024, 800)
    new_h_before_padding = crop_size_before_padding[0] * int(height / crop_size_before_padding[0])
    new_w_before_padding = crop_size_before_padding[1] * int(width / crop_size_before_padding[1])
    # å®šä¹‰è£å‰ªå°ºå¯¸
    padding_size = 32
    crop_size = (crop_size_before_padding[0] + padding_size * 2, crop_size_before_padding[1] + padding_size * 2)
    
    density_map_bgr = np.zeros((new_h_before_padding, new_w_before_padding, 3), dtype=np.float32)

    pred_count = 0
    for pred_imagename in pred_imagenames:
        # åŠ è½½å¯†åº¦å›¾ï¼Œdensity_mapé‡Œå­˜åœ¨è´Ÿæ•°å€¼ğŸ¤”
        density_map_path = os.path.join(pred_dir, pred_imagename)
        density_map = np.load(density_map_path)
        # å°†å¯†åº¦åœ°å›¾ä¸­çš„è´Ÿæ•°å€¼è®¾ä¸º0
        density_map[density_map < 0] = 0
        # æŠŠå¯†åº¦å›¾æ”¾ç¼©åˆ°cropå¤§å°
        original_sum = density_map.sum()
        print(original_sum)
        density_map_resized = cv2.resize(density_map, (crop_size[1], crop_size[0]))
        density_map_resized = density_map_resized / density_map_resized.sum() * original_sum
        # density_map_resized = cv2.resize(density_map, (crop_size[1], crop_size[0]))
        # åˆ‡å‰²å¯†åº¦å›¾
        parts = pred_imagename.split('_')
        imagename = '_'.join(parts[:-5])
        print(imagename)
        row = int(parts[-5])
        col = int(parts[-4])
        h_plus = float(parts[-3])
        h = int(h_plus / (h_plus + 1024) * 1024)
        density_map1 = density_map_resized[:-h, :]
        # æŠŠå¯†åº¦å›¾æ”¾ç¼©åˆ°cropçš„å¤§å°
        original_sum = density_map1.sum()
        print(original_sum)
        density_map1_resized = cv2.resize(density_map1, (crop_size[1], crop_size[0]))
        if original_sum > 0:     
            density_map1_resized = density_map1_resized / density_map1_resized.sum() * original_sum
        else:
            density_map1_resized = density_map1_resized * original_sum           
        # density_map1_resized = cv2.resize(density_map1, (crop_size[1], crop_size[0]))
        
        # å–ä¸­é—´çš„(1024, 800)
        # åŸå§‹å¯†åº¦å›¾çš„å¤§å°
        original_height, original_width = density_map1_resized.shape
        # æ–°å¯†åº¦å›¾çš„å¤§å°
        new_height, new_width = 1024, 800
        # è®¡ç®—è£å‰ªåŒºåŸŸçš„å·¦ä¸Šè§’åæ ‡
        start_x = (original_width - new_width) // 2
        start_y = (original_height - new_height) // 2
        # è£å‰ªå‡ºæ–°çš„å¯†åº¦å›¾
        new_density_map = density_map1_resized[start_y:start_y + new_height, start_x:start_x + new_width]
        print(np.sum(new_density_map))
        print("\n")
        pred_count += np.sum(new_density_map)

        # æ‹¼æ¥èµ‹å€¼ï¼Œå¯¹æœ‰æ•ˆå°ºå¯¸è¿›è¡Œæ‹¼æ¥
        density_map_bgr[row * crop_size_before_padding[0]:(row+1) * crop_size_before_padding[0], col * crop_size_before_padding[1]:(col+1) * crop_size_before_padding[1], 2] = new_density_map


    # å½’ä¸€åŒ–ï¼Œæ˜ å°„åˆ°255
    min_pixel = density_map_bgr[:, :, 2].min()
    max_pixel = density_map_bgr[:, :, 2].max()
    density_map_normalized = (density_map_bgr[:, :, 2] - min_pixel) / (max_pixel - min_pixel)

    density_map_bgr[:, :, 2] = density_map_normalized * 255
    # è·å–gtï¼šåˆ°density_mapä¸­è·å–
    original_density_map = torch.from_numpy(np.load(os.path.join(
        original_dir,
        'gt_density_map_adaptive_512_512_blueberry',
        imagename + '.npy',
    ))).unsqueeze(0)
    gt_count = float(original_density_map.flatten(1).sum(dim=1))

    # è®¾ç½®å­—ä½“å’Œæ–‡æœ¬å¤§å°
    h = original_image.shape[0]
    w = original_image.shape[1]
    font = cv2.FONT_HERSHEY_SIMPLEX
    font_scale = 3
    thickness = 14

    # å°†å¯†åº¦å›¾å åŠ åˆ°å›¾åƒä¸Š
    alpha = 0.5  # é€æ˜åº¦
    density_map_bgr_resized = cv2.resize(density_map_bgr, (width, height))
    density_map_bgr_resized = density_map_bgr_resized.astype(original_image.dtype)

    # ä¿å­˜å åŠ åçš„å¯†åº¦å›¾
    
    # åœ¨å›¾åƒä¸Šæ·»åŠ ç™½è‰²å­—ä½“çš„è®¡æ•°ç»“æœ
    cv2.putText(density_map_bgr_resized, f"GT Count: {gt_count:.3f}", (w-1000, h-100), font, font_scale, (255, 255, 255), thickness)
    cv2.putText(density_map_bgr_resized, f"Pred Count: {pred_count:.3f}", (w-1000, h-200), font, font_scale, (255, 255, 255), thickness)
    overlay = cv2.addWeighted(original_image, 1 - alpha, density_map_bgr_resized, alpha, 0)

    # ä¿å­˜å åŠ åçš„å›¾åƒ
    output_path = os.path.join(save_folder, 'overlay_' + imagename + ".jpg")
    cv2.imwrite(output_path, overlay)
    print(f"{imagename} æ‹¼æ¥å®Œæˆ...")

    # è®¡ç®—è¯„ä»·æŒ‡æ ‡
    ae += abs(gt_count - pred_count)
    se += (gt_count - pred_count) ** 2

logging.info(
    f"{split} set, "+
    f"MAE: {ae / len(imagenames):.2f}, " + 
    f"RMSE: {math.sqrt(se / len(imagenames)):.2f}"
)